{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Assignment on Melanoma Cancer Detection "
      ],
      "metadata": {
        "id": "bMKfUvfUWnny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Problem Statement\n",
        "- To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution that can evaluate images and alert dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
      ],
      "metadata": {
        "id": "7542WDoHODKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### About Dataset\n",
        "- The dataset consists of 2357 images of malignant and benign oncological diseases, which were formed from the International Skin Imaging Collaboration (ISIC). All images were sorted according to the classification taken with ISIC, and all subsets were divided into the same number of images, with the exception of melanomas and moles, whose images are slightly dominant."
      ],
      "metadata": {
        "id": "jf9sJulrP7Dc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The data set contains the following diseases:\n",
        "\n",
        "- Actinic keratosis\n",
        "- Basal cell carcinoma\n",
        "- Dermatofibroma\n",
        "- Melanoma\n",
        "- Nevus\n",
        "- Pigmented benign keratosis\n",
        "- Seborrheic keratosis\n",
        "- Squamous cell carcinoma\n",
        "- Vascular lesion"
      ],
      "metadata": {
        "id": "CfQJsJNxQ1--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing all required Libraries"
      ],
      "metadata": {
        "id": "NVS-VicSU3l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Data Processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# For Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# For other tasks\n",
        "import pathlib\n",
        "import os\n",
        "import PIL\n",
        "# For CNN\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "vajEhPaJQESd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob"
      ],
      "metadata": {
        "id": "BCVZzBXyWM_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing Dataset"
      ],
      "metadata": {
        "id": "SzkD29lbXWl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "Er621HMdWz4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Reading/Data Understanding\n",
        "- Defining the path for `train and test images`"
      ],
      "metadata": {
        "id": "L7XcFN55tagL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Assigning variables to the train and test datasets"
      ],
      "metadata": {
        "id": "mcIBgch6taAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = pathlib.Path(\"/content/gdrive/MyDrive/Colab-Notebooks/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train\")\n",
        "test_data_dir = pathlib.Path('/content/gdrive/MyDrive/Colab-Notebooks/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Test')"
      ],
      "metadata": {
        "id": "Ul7rtRj4iR_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Getting the list of images in each dataset"
      ],
      "metadata": {
        "id": "u3AjlEu_ti0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_count_train = len(list(train_data_dir.glob('*/*.jpg')))\n",
        "print(\"The total number of images in train dataset is:\",image_count_train)\n",
        "image_count_test = len(list(test_data_dir.glob('*/*.jpg')))\n",
        "print(\"The total number of images in test dataset is:\",image_count_test)"
      ],
      "metadata": {
        "id": "fNA1138Qkezj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Creation\n",
        "- Create `train & validation dataset` from the train directory with a batch size of 32. Also, make sure you resize your images to 180*180."
      ],
      "metadata": {
        "id": "QeHCaFUcugIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creating a Dataset"
      ],
      "metadata": {
        "id": "dmL5b2tzuS6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "aI8EagpwlEqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_data_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    class_names=None, \n",
        "    color_mode='rgb', \n",
        "    batch_size=batch_size, \n",
        "    image_size=(img_height, img_width),\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'training',\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ],
      "metadata": {
        "id": "f6mr2Dq_uwDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_data_dir, \n",
        "    labels='inferred', \n",
        "    label_mode='int',\n",
        "    class_names=None, \n",
        "    color_mode='rgb', \n",
        "    batch_size=batch_size, \n",
        "    image_size=(img_height, img_width),\n",
        "    shuffle=True, \n",
        "    seed=123,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'validation',\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ],
      "metadata": {
        "id": "KpyPvyOywUbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Getting the list of `class names` for train and test datasets."
      ],
      "metadata": {
        "id": "CIO8isNb-NAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "list(class_names)"
      ],
      "metadata": {
        "id": "tzlRGv9VxHXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = val_ds.class_names\n",
        "list(class_names)"
      ],
      "metadata": {
        "id": "o2TjpssEx0mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Getting the shape of the image_batch and labels_batch"
      ],
      "metadata": {
        "id": "71lyTIVd-TaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "-epn18FAwfks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset visualisation\n",
        "- Create a code to visualize one instance of all the nine classes present in the dataset "
      ],
      "metadata": {
        "id": "54aKEJY5uc4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "uz7qrRgHSQmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images."
      ],
      "metadata": {
        "id": "JLHojZTK-24c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "\n",
        "`Dataset.prefetch()` overlaps data preprocessing and model execution while training."
      ],
      "metadata": {
        "id": "kw8IfT6_-2mY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "0PeCXrsjTyun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building & training\n",
        "- Create a CNN model, which can accurately detect 9 classes present in the dataset. While building the model, rescale images to normalize pixel values between (0,1)."
      ],
      "metadata": {
        "id": "gUnAVCOZW7Ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Standardize Data of RGB channel value\n",
        "# normalization_layer = layers.Rescaling(1./255)\n",
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]"
      ],
      "metadata": {
        "id": "4inwQT0nBx6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "metadata": {
        "id": "CQb5ffHwCdO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_class = len(class_names)\n",
        "model = Sequential([\n",
        "    layers.Rescaling(scale = 1./255, input_shape = (img_height,img_width,3)),\n",
        "    layers.Conv2D(16,3,padding='same',activation= 'relu'),\n",
        "    layers.Conv2D(32,3,padding='same',activation= 'relu'),\n",
        "    layers.Conv2D(64,3,padding='same',activation= 'relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128,activation='relu'),\n",
        "    layers.Dense(num_class)\n",
        "])"
      ],
      "metadata": {
        "id": "X40_BHakWUkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "          metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "41nNElKhXAmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "HyCLiP2bXQuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "SgCFTx_HzsYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_P40mi0fzt5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As the model is overfitting, lets due the agumentation to reduce the overfitting\n",
        "# Let's use random flip, rotate and zoom for agumentation\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\",input_shape=(img_height,img_width,3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1)])"
      ],
      "metadata": {
        "id": "smUpCl1O1QLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize how your augmentation strategy works for one instance of training image.\n",
        "# setting the output image size\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "ARc-BuwDFGKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## You can use Dropout layer if there is an evidence of overfitting in your findings\n",
        "# Let's add some dropout layers to the model as our model is overfitting\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_class, name=\"outputs\")\n",
        "])"
      ],
      "metadata": {
        "id": "o-tZvgG5FL5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## compiling the model with adam optinizer and crossentropy for loss function and accuracy as metrics\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "# printing the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "qwsAXmORFjX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "GGAyh_WJFjFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kKaTpf2mF_8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installing the Agumentor\n",
        "!pip install Augmentor"
      ],
      "metadata": {
        "id": "DGn8qzHYHmjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the agumentor package \n",
        "import Augmentor\n",
        "\n",
        "# taking the Training dataset path\n",
        "# path_to_training_dataset='gdrive/My Drive/Colab Notebooks/Skin cancer ISIC The International Skin Imaging Collaboration/Train/'\n",
        "training_path=\"/content/gdrive/MyDrive/Colab-Notebooks/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\"\n",
        "\n",
        "for i in class_names:\n",
        "  # instantiating the pipeline object with training dataset for a specific class\n",
        "    p = Augmentor.Pipeline(training_path + i)\n",
        "    # rotating the image\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    # We are adding 500 samples per class to make sure that none of the classes are sparse.\n",
        "    p.sample(500) "
      ],
      "metadata": {
        "id": "zu1A8hSKIpQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# again printing the image count in training dataset\n",
        "image_count_train = len(list(train_data_dir.glob('*/output/*.jpg')))\n",
        "print(f'Number of images in training dataset: {image_count_train}')"
      ],
      "metadata": {
        "id": "BvPoJK3IIs1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating path list\n",
        "path_list = [x for x in glob(os.path.join(train_data_dir, '*','output', '*.jpg'))]\n",
        "len(path_list)"
      ],
      "metadata": {
        "id": "Y8G-8mM0MxVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# taking the skin cancer type in a list\n",
        "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob(os.path.join(train_data_dir, '*','output', '*.jpg'))]\n",
        "len(lesion_list_new)"
      ],
      "metadata": {
        "id": "WkzwvgyiNg49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a new dictionary with the file path and class type\n",
        "dataframe_dict_new = dict(zip(path_list, lesion_list_new))"
      ],
      "metadata": {
        "id": "O4ZM1UZNP243"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dataframe with the above dictionary\n",
        "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\n",
        "new_df = df2\n",
        "# new_df = original_df.append(df2)"
      ],
      "metadata": {
        "id": "rxzPLNZwP2rR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the number of images under each type\n",
        "new_df['Label'].value_counts()"
      ],
      "metadata": {
        "id": "KIvgzGItP2Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_data_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    class_names=None, \n",
        "    color_mode='rgb', \n",
        "    batch_size=batch_size, \n",
        "    image_size=(img_height, img_width),\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'training',\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ],
      "metadata": {
        "id": "JH39CZXzQFPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_data_dir, \n",
        "    labels='inferred', \n",
        "    label_mode='int',\n",
        "    class_names=None, \n",
        "    color_mode='rgb', \n",
        "    batch_size=batch_size, \n",
        "    image_size=(img_height, img_width),\n",
        "    shuffle=True, \n",
        "    seed=123,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'validation',\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ],
      "metadata": {
        "id": "1_TC6pW-QbEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# performing autotune\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "#normalizing the Data\n",
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))\n",
        "\n",
        "# creating a model post handling the imbalancing\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_class)\n",
        "])"
      ],
      "metadata": {
        "id": "XEDwjcMJQjEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "V92yhRzuQ_xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets train the model with 30 epochs\n",
        "epochs = 30\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "-v0P5sOGRMsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oAkx1gD6RSdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wFWmFieaSmjG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}